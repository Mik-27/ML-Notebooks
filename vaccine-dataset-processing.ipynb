{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-07T14:58:04.15343Z","iopub.execute_input":"2021-06-07T14:58:04.153856Z","iopub.status.idle":"2021-06-07T14:58:04.167633Z","shell.execute_reply.started":"2021-06-07T14:58:04.153752Z","shell.execute_reply":"2021-06-07T14:58:04.166559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/vacdatasetprocessing/Vaccinations.csv\")\ndf_india = pd.read_csv(\"/kaggle/input/vacdatasetprocessing/India.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-06-07T15:21:52.46489Z","iopub.execute_input":"2021-06-07T15:21:52.465302Z","iopub.status.idle":"2021-06-07T15:21:52.527527Z","shell.execute_reply.started":"2021-06-07T15:21:52.465265Z","shell.execute_reply":"2021-06-07T15:21:52.526564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_india","metadata":{"execution":{"iopub.status.busy":"2021-06-07T15:21:52.529987Z","iopub.execute_input":"2021-06-07T15:21:52.530433Z","iopub.status.idle":"2021-06-07T15:21:52.548742Z","shell.execute_reply.started":"2021-06-07T15:21:52.530387Z","shell.execute_reply":"2021-06-07T15:21:52.54772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df[df['location'] == 'India']\ndf.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T15:21:52.550379Z","iopub.execute_input":"2021-06-07T15:21:52.550795Z","iopub.status.idle":"2021-06-07T15:21:52.581596Z","shell.execute_reply.started":"2021-06-07T15:21:52.550751Z","shell.execute_reply":"2021-06-07T15:21:52.580382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df['date'].isin(df_india['date']) == False]","metadata":{"execution":{"iopub.status.busy":"2021-06-07T15:29:31.900772Z","iopub.execute_input":"2021-06-07T15:29:31.901126Z","iopub.status.idle":"2021-06-07T15:29:31.922552Z","shell.execute_reply.started":"2021-06-07T15:29:31.901095Z","shell.execute_reply":"2021-06-07T15:29:31.921453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_india.date = pd.to_datetime(df_india.date)\ndf.date = pd.to_datetime(df.date)","metadata":{"execution":{"iopub.status.busy":"2021-06-07T15:21:56.492061Z","iopub.execute_input":"2021-06-07T15:21:56.492425Z","iopub.status.idle":"2021-06-07T15:21:56.499661Z","shell.execute_reply.started":"2021-06-07T15:21:56.492396Z","shell.execute_reply":"2021-06-07T15:21:56.498504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_india[['date', 'vaccine', 'source_url']]","metadata":{"execution":{"iopub.status.busy":"2021-06-07T15:39:17.280239Z","iopub.execute_input":"2021-06-07T15:39:17.280603Z","iopub.status.idle":"2021-06-07T15:39:17.298848Z","shell.execute_reply.started":"2021-06-07T15:39:17.280571Z","shell.execute_reply":"2021-06-07T15:39:17.297653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.merge(df_india[['date', 'vaccine', 'source_url']], left_on='date', right_on='date', how='left')\n# df.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-07T15:39:24.523993Z","iopub.execute_input":"2021-06-07T15:39:24.524497Z","iopub.status.idle":"2021-06-07T15:39:24.565526Z","shell.execute_reply.started":"2021-06-07T15:39:24.524459Z","shell.execute_reply":"2021-06-07T15:39:24.564698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\ndef merge_data():\n    \n    # Importing Data\n    df_india = pd.read_csv(\"..\\Raw Data\\India.csv\")\n    df_world = pd.read_csv(\"..\\Raw Data\\Vaccinations.csv\")\n    \n    # Adding row for missing date viz. 2021-04-20\n    missed_date = pd.DataFrame({'date':'2021-04-20', 'location':'India', 'vaccine':'Covaxin, Oxford/AstraZeneca'}, index=[93.5])\n    df_india = df_india.append(missed_date, ignore_index=False)\n    df_india = df_india.sort_index().reset_index(drop=True)\n    \n    # Drop data for date = '2021-02-14'\n    df_world.drop(df_world[(df_world['location'] == 'India') & (df_world['date'] == '2021-02-14')].index[0], axis=0, inplace=True)\n    \n    # Get useful columns\n    useful_df = df_world[df_world['location'] == 'India'].iloc[:,7:]\n    useful_df = useful_df.reset_index()\n    udf_cols = useful_df.columns.tolist()\n    udf_cols.remove('index')\n    \n    # Merge/concat data from the two tables\n    df = pd.concat([df_india, useful_df], axis=1, ignore_index=True)\n    df.drop([7], axis=1, inplace=True)\n    \n    df_cols = df_india.columns.tolist()\n    df_cols.extend(udf_cols)\n    \n    df.columns = df_cols\n    \n    #Preprocessing - Missing values\n    df.date = pd.to_datetime(df['date'])\n    df.loc[1,\"people_fully_vaccinated_per_hundred\"] = 0.0\n    df[\"people_fully_vaccinated_per_hundred\"] = df[\"people_fully_vaccinated_per_hundred\"].fillna(method='bfill')\n    df[\"change\"] = df.daily_vaccinations.diff()\n    df.rename({'change': 'daily_change_in_vaccinations'}, axis=1, inplace=True)\n    df.fillna(0, inplace=True)\n    cols = df.columns.to_list()\n    \n    # Final columns list\n    cols = ['location',\n     'date',\n     'vaccine',\n     'source_url',\n     'total_vaccinations',\n     'total_vaccinations_per_hundred',\n     'people_vaccinated',\n     'people_vaccinated_per_hundred',\n     'people_fully_vaccinated',\n     'people_fully_vaccinated_per_hundred',       \n     'daily_vaccinations',\n     'daily_change_in_vaccinations',\n     'daily_vaccinations_per_million',\n     ]\n    df = df[cols]\n    \n    df.to_csv(\"..\\Processed Data\\Covid-19_Daily_Vaccinations_India.csv\")\n    \n# merge_data()\n","metadata":{},"execution_count":null,"outputs":[]}]}